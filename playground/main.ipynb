{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53682e3e",
   "metadata": {},
   "source": [
    "## Import and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a38cd81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/egorfolley/TechDev/.env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json\n",
    "import PyPDF2\n",
    "from langchain_xai import ChatXAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abd28632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up LLM (Grok)\n",
    "llm = ChatXAI(model=\"grok-4-1-fast-reasoning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7935b7ae",
   "metadata": {},
   "source": [
    "## Extracting text from PDF and classifying "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e49ed383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a func to extract email components from PDF\n",
    "def load_pdf(pdf_path: str) -> str:\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = ''\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() + '\\n'\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def extract_email_data(email_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Intake: Extract text from PDF and parse into email components.\n",
    "    Assumes simple Gmail-style format as in samples.\n",
    "    \"\"\"    \n",
    "    # Clean and parse (heuristic based on sample format)\n",
    "    lines = [line.strip() for line in email_text.split('\\n') if line.strip()]\n",
    "    \n",
    "    # Extract From\n",
    "    from_line = next((line for line in lines if line.startswith('From:')), None)\n",
    "    sender = from_line.replace('From:', '').strip() if from_line else 'Unknown'\n",
    "    \n",
    "    # Extract Subject\n",
    "    subject_line = next((line for line in lines if line.startswith('Subject:')), None)\n",
    "    subject = subject_line.replace('Subject:', '').strip() if subject_line else 'No Subject'\n",
    "    \n",
    "    # Extract Body (everything after Subject until signature)\n",
    "    body_start = lines.index(subject_line) + 1 if subject_line else 1\n",
    "    body_lines = lines[body_start:]\n",
    "    # Assume signature starts with 'Best regards,' or similar; stop before\n",
    "    body_end = next((i for i, line in enumerate(body_lines) if 'Best regards,' in line or 'Thanks,' in line), len(body_lines))\n",
    "    body = '\\n'.join(body_lines[:body_end]).strip()\n",
    "    \n",
    "    return {\n",
    "        'sender': sender,\n",
    "        'subject': subject,\n",
    "        'body': body\n",
    "    }\n",
    "\n",
    "\n",
    "# Email classificaion func\n",
    "def classify_email(email_data: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Processing: Classify urgency (P1/P2/P3) and topic/domain using Gemini LLM.\n",
    "    Domains examples: billing, support, outage, product, etc.\n",
    "    \"\"\"\n",
    "    prompt_template = \"\"\"\n",
    "        Analyze this email:\n",
    "        Subject: {subject}\n",
    "        Body: {body}\n",
    "        \n",
    "        Classify:\n",
    "        - Urgency: P1 (critical, immediate impact), P2 (high, affects operations), P3 (low, informational)\n",
    "        - Topic: One main domain (e.g., billing, platform outage, support, product issue)\n",
    "        - Keywords: 3-5 key entities/phrases\n",
    "        \n",
    "        Output as JSON: {{\"urgency\": \"P1\", \"topic\": \"billing\", \"keywords\": [\"invoice\", \"delay\", \"cash flow\"]}}\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate.from_template(prompt_template)\n",
    "    chain = prompt | llm\n",
    "    \n",
    "    response = chain.invoke({\n",
    "        \"subject\": email_data['subject'],\n",
    "        \"body\": email_data['body']\n",
    "    })\n",
    "    \n",
    "    # Parse the response content\n",
    "    content = response.content.strip()\n",
    "    \n",
    "    # Remove markdown code block if present\n",
    "    if content.startswith('```json'):\n",
    "        content = content[7:]\n",
    "    if content.endswith('```'):\n",
    "        content = content[:-3]\n",
    "    content = content.strip()\n",
    "    \n",
    "    try:\n",
    "        classification = json.loads(content)\n",
    "        return classification\n",
    "    except json.JSONDecodeError:\n",
    "        return {\n",
    "            \"error\": \"Failed to parse JSON response\",\n",
    "            \"raw_response\": response.content\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e243acf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'urgency': 'P1',\n",
       " 'topic': 'platform outage',\n",
       " 'keywords': ['9:30 AM EST',\n",
       "  'two hours',\n",
       "  'critical dashboards',\n",
       "  'outage cause']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_test = load_pdf('../backend/test_data/gmail_style_email_2.pdf')\n",
    "email_data = extract_email_data(email_test)\n",
    "email_clf = classify_email(email_data)\n",
    "\n",
    "email_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302cc73c",
   "metadata": {},
   "source": [
    "## Storing email data in Milvus and Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05220efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import json\n",
    "from sqlalchemy import create_engine, text\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from llama_index.core import Document, VectorStoreIndex, StorageContext\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b65f7928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB Connection (sqlite for faster prototyping)\n",
    "SQLITE_URI = \"sqlite:///emails.db\"  # File-based DB, creates 'emails.db' if not exists\n",
    "engine = create_engine(SQLITE_URI)\n",
    "\n",
    "# Initialize table if not exists (run once or on startup)\n",
    "with engine.connect() as conn:\n",
    "    conn.execute(text(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS emails (\n",
    "            id TEXT PRIMARY KEY,\n",
    "            sender TEXT,\n",
    "            subject TEXT,\n",
    "            body TEXT,\n",
    "            urgency TEXT,\n",
    "            topic TEXT,\n",
    "            keywords TEXT  -- Stored as JSON string\n",
    "        )\n",
    "    \"\"\"))\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "def store_relational_data(email_id, keywords_json, email_data, classification):\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT INTO emails (id, sender, subject, body, urgency, topic, keywords)\n",
    "            VALUES (:id, :sender, :subject, :body, :urgency, :topic, :keywords)\n",
    "        \"\"\"), {\n",
    "            'id': email_id,\n",
    "            'sender': email_data['sender'],\n",
    "            'subject': email_data['subject'],\n",
    "            'body': email_data['body'],\n",
    "            'urgency': classification['urgency'],\n",
    "            'topic': classification['topic'],\n",
    "            'keywords': keywords_json\n",
    "        })\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fedb269c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/egorfolley/TechDev/.env/lib/python3.13/site-packages/milvus_lite/__init__.py:15: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n"
     ]
    }
   ],
   "source": [
    "# VectorDB connection \n",
    "MILVUS_URI = \"/Users/egorfolley/TechDev/customer_support_agent/backend/vectorDB/test_vecDB.db\"\n",
    "vector_store = MilvusVectorStore(\n",
    "    uri=MILVUS_URI,\n",
    "    collection_name=\"email_vectors\",\n",
    "    dim=384,\n",
    "    embedding_field=\"embedding\",\n",
    "    overwrite=False,  # use True only if recreating\n",
    ")\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store,\n",
    "    embed_model=embed_model,\n",
    "    storage_context=storage_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad923f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_email(email_data, classification):\n",
    "    \"\"\"\n",
    "    Store metadata + keywords + urgency + topic in VectorDB (Milvus) and Relational DB (SQLite).\n",
    "    - SQLite: Raw email, structured metadata (urgency, topic, keywords as JSON string).\n",
    "    - Milvus: Embeddings of summary/metadata for RAG retrieval.\n",
    "    \"\"\"\n",
    "    # Check if classification failed\n",
    "    if 'error' in classification:\n",
    "        return {\"error\": \"Classification failed\", \"details\": classification}\n",
    "    \n",
    "    # Generate unique ID\n",
    "    email_id = str(uuid.uuid4())\n",
    "    \n",
    "    # Store relational data\n",
    "    keywords_json = json.dumps(classification['keywords'])  # Store list as JSON string\n",
    "    with engine.connect() as conn:\n",
    "        conn.execute(text(\"\"\"\n",
    "            INSERT INTO emails (id, sender, subject, body, urgency, topic, keywords)\n",
    "            VALUES (:id, :sender, :subject, :body, :urgency, :topic, :keywords)\n",
    "        \"\"\"), {\n",
    "            'id': email_id,\n",
    "            'sender': email_data['sender'],\n",
    "            'subject': email_data['subject'],\n",
    "            'body': email_data['body'],\n",
    "            'urgency': classification['urgency'],\n",
    "            'topic': classification['topic'],\n",
    "            'keywords': keywords_json\n",
    "        })\n",
    "        conn.commit()\n",
    "\n",
    "    # Create a summary for embedding (title + topic + urgency + key parts)\n",
    "    summary = f\"Subject: {email_data['subject']}\\nUrgency: {classification['urgency']}\\nTopic: {classification['topic']}\\nKeywords: {', '.join(classification['keywords'])}\\nBody Snippet: {email_data['body'][:200]}...\"\n",
    "    \n",
    "    # Store in Milvus (vector) using LlamaIndex for embedding and indexing\n",
    "    doc = Document(\n",
    "        text=summary,\n",
    "        metadata={\n",
    "            \"email_id\": email_id,\n",
    "            \"urgency\": classification['urgency'],\n",
    "            \"topic\": classification['topic']\n",
    "        },\n",
    "        id_=email_id\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Index with embeddings (LlamaIndex handles embedding via embed_model if set, but here we specify)\n",
    "    index = VectorStoreIndex.from_documents(\n",
    "        [doc],\n",
    "        storage_context=storage_context,\n",
    "        embed_model=embed_model  # Use Gemini-compatible embeddings\n",
    "    )\n",
    "    output = {\"email_id\": email_id, \"stored\": True, \"storage_context\": storage_context}\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3536763c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1768798915.325581  477414 fork_posix.cc:71] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    }
   ],
   "source": [
    "# Email -> data -> classification -> NOW store\n",
    "email_store = store_email(email_data=email_data, classification=email_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ff861f",
   "metadata": {},
   "source": [
    "## Summarization and RAG Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ccea25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c9c6265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools\n",
    "@tool\n",
    "def rag_retrieval(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve similar historical emails from the vector database using semantic search.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query based on topic, urgency, keywords.\n",
    "    \n",
    "    Returns:\n",
    "        str: Concatenated text of top 5 similar cases.\n",
    "    \"\"\"\n",
    "    retriever = index.as_retriever()\n",
    "    retrieved_docs = retriever.retrieve(query)\n",
    "    similar_cases = \"\\n\".join([doc.text for doc in retrieved_docs[:5]])\n",
    "    return similar_cases if similar_cases else \"No similar cases found.\"\n",
    "\n",
    "@tool\n",
    "def draft_support_response(email_data: dict, classification: dict, diagnostic: dict) -> str:\n",
    "    \"\"\"\n",
    "    Draft a professional customer support response based on email data, classification, and diagnostic.\n",
    "    \n",
    "    Args:\n",
    "        email_data (dict): Parsed email data.\n",
    "        classification (dict): Classification result.\n",
    "        diagnostic (dict): Diagnostic output.\n",
    "    \n",
    "    Returns:\n",
    "        str: Drafted response text.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following, draft a professional customer support response.\n",
    "    \n",
    "    Email Subject: {email_data['subject']}\n",
    "    Email Body: {email_data['body']}\n",
    "    Urgency: {classification['urgency']}\n",
    "    Topic: {classification['topic']}\n",
    "    Problem Statement: {diagnostic['problem_statement']}\n",
    "    \n",
    "    Acknowledge the issue, provide next steps, and include a title.\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content.strip()\n",
    "\n",
    "@tool\n",
    "def search_past_similar_tickets(topic: str, urgency: str) -> str:\n",
    "    \"\"\"\n",
    "    Search the relational database for past similar tickets based on topic and urgency.\n",
    "    \n",
    "    Args:\n",
    "        topic (str): The topic of the ticket.\n",
    "        urgency (str): The urgency level.\n",
    "    \n",
    "    Returns:\n",
    "        str: List of similar tickets as JSON strings.\n",
    "    \"\"\"\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(\"\"\"\n",
    "            SELECT id, sender, subject, body, keywords FROM emails\n",
    "            WHERE topic = :topic AND urgency = :urgency\n",
    "            LIMIT 5\n",
    "        \"\"\"), {'topic': topic, 'urgency': urgency})\n",
    "        tickets = [dict(row) for row in result]\n",
    "    return json.dumps(tickets) if tickets else \"No similar tickets found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28249d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ww/d2xxjh3s0y3dhb878qz0n5z80000gn/T/ipykernel_44219/3540264450.py:12: LangGraphDeprecatedSinceV10: create_react_agent has been moved to `langchain.agents`. Please update your import to `from langchain.agents import create_agent`. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  agent = create_react_agent(llm, tools, prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "# Agent setup\n",
    "tools = [rag_retrieval, draft_support_response, search_past_similar_tickets]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI assistant for customer support. \"\n",
    "                \"Use the tools to analyze the email, retrieve similar historical cases, and search past tickets. \"\n",
    "                \"Based on the analysis, create suggestions on how to fix the issue described in the email. \"\n",
    "                \"Output structured JSON with diagnostics and fix suggestions.\"),\n",
    "    MessagesPlaceholder(\"messages\"),\n",
    "])\n",
    "\n",
    "agent = create_react_agent(llm, tools, prompt=prompt)\n",
    "\n",
    "# agent = create_react_agent(llm, tools, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f47cd179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"email_data\": {\n",
      "    \"subject\": \"Support Ticket #4832 – No Response Yet\",\n",
      "    \"body\": \"Hi Support Team,\\nI’m following up on ticket #4832, which we opened last week. We haven’t received any response so far,\\nand the issue is still blocking our workflow.\\nCould someone please take a look and let us know when we can expect help?\\nThank you,\\nDavid Morales\\nProduct Lead, ClearPath AI\",\n",
      "    \"urgency\": \"P2\",\n",
      "    \"topic\": \"support\"\n",
      "  },\n",
      "  \"diagnostics\": {\n",
      "    \"issue_type\": \"follow-up on unanswered ticket\",\n",
      "    \"ticket_id\": \"4832\",\n",
      "    \"customer_sentiment\": \"frustrated\",\n",
      "    \"impact\": \"blocking workflow\",\n",
      "    \"time_since_open\": \"last week\",\n",
      "    \"similar_cases\": \"No highly similar historical cases found. Retrieved case on platform outage (P1) not matching.\",\n",
      "    \"past_tickets\": \"No similar tickets found for topic 'support' and urgency 'P2'.\"\n",
      "  },\n",
      "  \"fix_suggestions\": [\n",
      "    \"Immediately retrieve and review the details of ticket #4832 to understand the original issue.\",\n",
      "    \"Assign the ticket to a qualified support agent if not already assigned.\",\n",
      "    \"Respond to the customer within 4 hours (P2 SLA recommendation) with an apology for the delay, current status update, and estimated time to resolution (ETA).\",\n",
      "    \"Escalate if the original issue requires engineering involvement.\",\n",
      "    \"Implement process improvement: Set up auto-acknowledgment for new tickets and alerts for unresponded tickets after 48 hours.\",\n",
      "    \"Update ticket status to 'In Progress' and notify the customer of next steps.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Execution example\n",
    "email_test = load_pdf('../backend/test_data/gmail_style_email_4.pdf')\n",
    "email_data = extract_email_data(email_test)\n",
    "email_clf = classify_email(email_data)\n",
    "\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=f\"Process this email: subject '{email_data['subject']}', body '{email_data['body']}', urgency '{email_clf['urgency']}', topic '{email_clf['topic']}'.\")],\n",
    "}\n",
    "\n",
    "result = agent.invoke(initial_state)\n",
    "print(result['messages'][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
